{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Assignment 2: Build a CNN for image recognition.\n",
    "\n",
    "## Due Date:  March 31, 11:59PM\n",
    "\n",
    "### Name: [Sri Naga Hansi Mamidi]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "1. In this assignment, you will build Convolutional Neural Network to classify CIFAR-10 Images.\n",
    "2. You can directly load dataset from many deep learning packages.\n",
    "3. You can use any deep learning packages such as pytorch, keras or tensorflow for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements:\n",
    "\n",
    "1. You need to load cifar 10 data and split the entire training dataset into training and validation.\n",
    "2. You will implement a CNN model to classify cifar 10 images with provided structure.\n",
    "3. You need to plot the training and validation accuracy or loss obtained from above step.\n",
    "4. Then you can use tuned hyper-parameters to train using the entire training dataset.\n",
    "5. You should report the testing accuracy using the model with complete data.\n",
    "6. You may try to change the structure (e.g, add BN layer or dropout layer,...) and analyze your findings.\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization (BN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Batch Normalization is a technique to speed up training and help make the model more stable.\n",
    "- In simple words, batch normalization is just another network layer that gets inserted between a hidden layer and the next hidden layer. Its job is to take the outputs from the first hidden layer and normalize them before passing them on as the input of the next hidden layer.\n",
    "\n",
    "- For more detailed information, you may refer to the original paper: https://arxiv.org/pdf/1502.03167.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BN Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: Values of $x$ over a mini-batch: $\\mathbf{B}$ = $\\{x_1,..., x_m\\};$\n",
    "- Output: $\\{y_i = BN_{\\gamma,\\beta}(x_i)\\}$, $\\gamma, \\beta$ are learnable parameters\n",
    "\n",
    "Normalization of the Input:\n",
    "$$\\mu_{\\mathbf{B}} = \\frac{1}{m}\\sum_{i=1}^m x_i$$\n",
    "$$\\sigma_{\\mathbf{B}}^2 = \\frac{1}{m}\\sum_{i=1}^m (x_i - \\mu_{\\mathbf{B}})^2$$\n",
    "$$\\hat{x_i} = \\frac{x_i - \\mu_{\\mathbf{B}}}{\\sqrt{\\sigma_{\\mathbf{B}}}^2 + \\epsilon}$$\n",
    "Re-scaling and Offsetting:\n",
    "$$y_i = \\gamma \\hat{x_i} + \\beta = BN_{\\gamma,\\beta}(x_i)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of BN:\n",
    "1. Improves gradient flow through the network.\n",
    "2. Allows use of saturating nonlinearities and higher learning rates.\n",
    "3. Makes weights easier to initialize.\n",
    "4. Act as a form of regularization and may reduce the need for dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The batch normalization layer has already been implemented in many packages. You may simply call the function to build the layer. For example: torch.nn.BatchNorm2d() using pytroch package, keras.layers.BatchNormalization() using keras package.\n",
    "- The location of BN layer: Please make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Load Cifar-10 Data\n",
    "# This is just an example, you may load dataset from other packages.\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "### If you can not load keras dataset, un-comment these two lines.\n",
    "#import ssl\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train_vec is(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train_vec = x_train.reshape((50000,32,32,3))\n",
    "x_test_vec = x_test.reshape((10000,32,32,3))\n",
    "\n",
    "print('Shape of x_train_vec is'+ str(x_train_vec.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels (5 points)\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Implement a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    results = np.zeros((len(y),num_class))\n",
    "    for i, label in enumerate(y):\n",
    "        results[i, label] = 1\n",
    "    return results\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets (5 points)\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets: \n",
    "* a training set containing 40K samples: x_tr, y_tr\n",
    "* a validation set containing 10K samples: x_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27951 43461 22632 ... 30316 37486 29253] (50000, 32, 32, 3)\n",
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = np.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "print(valid_indices,x_train_vec.shape)\n",
    "x_val = x_train_vec[valid_indices, :, :, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train_vec[train_indices, :, :, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters (50 points)\n",
    "\n",
    "- Build a convolutional neural network model using the below structure:\n",
    "\n",
    "- It should have a structure of: Conv - ReLU - Max Pool - ConV - ReLU - Max Pool - Dense - ReLU - Dense - Softmax\n",
    "\n",
    "- In the graph 3@32x32 means the dimension of input image, 32@30x30 means it has 32 filters and the dimension now becomes 30x30 after the convolution.\n",
    "- All convolutional layers (Conv) should have stride = 1 and no padding.\n",
    "- Max Pooling has a pool size of 2 by 2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"network.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You may use the validation data to tune the hyper-parameters (e.g., learning rate, and optimization algorithm)\n",
    "- Do NOT use test data for hyper-parameter tuning!!!\n",
    "- Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               590080    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 626,378\n",
      "Trainable params: 626,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (4,4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model optimizer and loss function\n",
    "from keras import optimizers\n",
    "model.compile(optimizers.RMSprop(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 15s 35ms/step - loss: 4.2256 - accuracy: 0.2855 - val_loss: 1.7175 - val_accuracy: 0.4103\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.5493 - accuracy: 0.4607 - val_loss: 1.3521 - val_accuracy: 0.5306\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.2942 - accuracy: 0.5488 - val_loss: 1.1592 - val_accuracy: 0.5980\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.1371 - accuracy: 0.6065 - val_loss: 0.9880 - val_accuracy: 0.6589\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.0144 - accuracy: 0.6486 - val_loss: 0.8874 - val_accuracy: 0.6972\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.9096 - accuracy: 0.6867 - val_loss: 0.8544 - val_accuracy: 0.7055\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.8189 - accuracy: 0.7200 - val_loss: 0.6935 - val_accuracy: 0.7645\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.7322 - accuracy: 0.7502 - val_loss: 0.7460 - val_accuracy: 0.7446\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6570 - accuracy: 0.7786 - val_loss: 0.5914 - val_accuracy: 0.8003\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.5870 - accuracy: 0.8026 - val_loss: 0.5440 - val_accuracy: 0.8165\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.5224 - accuracy: 0.8246 - val_loss: 0.4631 - val_accuracy: 0.8461\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.4628 - accuracy: 0.8475 - val_loss: 0.3714 - val_accuracy: 0.8898\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 0.4069 - accuracy: 0.8668 - val_loss: 0.2954 - val_accuracy: 0.9137\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.3545 - accuracy: 0.8874 - val_loss: 0.3035 - val_accuracy: 0.9098\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.3106 - accuracy: 0.9027 - val_loss: 0.2332 - val_accuracy: 0.9338\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.2668 - accuracy: 0.9177 - val_loss: 0.2178 - val_accuracy: 0.9365\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.2287 - accuracy: 0.9325 - val_loss: 0.1681 - val_accuracy: 0.9583\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.1945 - accuracy: 0.9434 - val_loss: 0.1534 - val_accuracy: 0.9590\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.1644 - accuracy: 0.9540 - val_loss: 0.1094 - val_accuracy: 0.9774\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.1396 - accuracy: 0.9616 - val_loss: 0.0836 - val_accuracy: 0.9851\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 0.1159 - accuracy: 0.9691 - val_loss: 0.0726 - val_accuracy: 0.9869\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.0974 - accuracy: 0.9753 - val_loss: 0.0827 - val_accuracy: 0.9812\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.0812 - accuracy: 0.9799 - val_loss: 0.0476 - val_accuracy: 0.9937\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 0.0688 - accuracy: 0.9842 - val_loss: 0.0497 - val_accuracy: 0.9909\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.0591 - accuracy: 0.9860 - val_loss: 0.0409 - val_accuracy: 0.9932\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.0477 - accuracy: 0.9907 - val_loss: 0.0481 - val_accuracy: 0.9896\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.0407 - accuracy: 0.9918 - val_loss: 0.0209 - val_accuracy: 0.9980\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.0366 - accuracy: 0.9925 - val_loss: 0.0253 - val_accuracy: 0.9960\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.0302 - accuracy: 0.9937 - val_loss: 0.0266 - val_accuracy: 0.9936\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0307 - accuracy: 0.9931 - val_loss: 0.0123 - val_accuracy: 0.9993\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.0239 - accuracy: 0.9953 - val_loss: 0.0370 - val_accuracy: 0.9907\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0223 - accuracy: 0.9952 - val_loss: 0.0072 - val_accuracy: 0.9997\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.0203 - accuracy: 0.9955 - val_loss: 0.0098 - val_accuracy: 0.9991\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.0180 - accuracy: 0.9962 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.0171 - accuracy: 0.9960 - val_loss: 0.0258 - val_accuracy: 0.9926\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0156 - accuracy: 0.9964 - val_loss: 0.0094 - val_accuracy: 0.9986\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0132 - accuracy: 0.9971 - val_loss: 0.1163 - val_accuracy: 0.9594\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.0041 - val_accuracy: 0.9999\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.0033 - val_accuracy: 0.9998\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.0544 - val_accuracy: 0.9817\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0448 - val_accuracy: 0.9830\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0037 - val_accuracy: 0.9996\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.0018 - val_accuracy: 0.9999\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.0160 - val_accuracy: 0.9960\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.0936 - val_accuracy: 0.9670\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.0622 - val_accuracy: 0.9802\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.0031 - val_accuracy: 0.9997\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 14s 35ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0098 - val_accuracy: 0.9973\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store model parameters/loss values\n",
    "history = model.fit(x_train_vec, y_train_vec, batch_size=128, epochs=50, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot the training and validation loss curve versus epochs. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = range(50)\n",
    "train_loss = history.history['loss']\n",
    "valid_loss = history.history['val_loss']\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, valid_loss, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train (again) and evaluate the model (5 points)\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<Compile your model again (using the same hyper-parameters you tuned above)>\n",
    "model.compile(optimizers.RMSprop(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 16s 37ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.0481 - val_accuracy: 0.9840\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0023 - val_accuracy: 0.9999\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 13s 34ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0032 - val_accuracy: 0.9996\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0257 - val_accuracy: 0.9919\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.0174 - val_accuracy: 0.9942\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0031 - val_accuracy: 0.9990\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0446 - val_accuracy: 0.9856\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0105 - val_accuracy: 0.9966\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0089 - val_accuracy: 0.9972\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0087 - val_accuracy: 0.9979\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.2550 - val_accuracy: 0.9327\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0136 - val_accuracy: 0.9957\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0099 - val_accuracy: 0.9966\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0127 - val_accuracy: 0.9959\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0118 - val_accuracy: 0.9955\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 6.1617e-04 - val_accuracy: 0.9999\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0079 - val_accuracy: 0.9979\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0080 - val_accuracy: 0.9974\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0069 - val_accuracy: 0.9978\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0047 - val_accuracy: 0.9986\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 6.3263e-04 - val_accuracy: 0.9999\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0091 - val_accuracy: 0.9969\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0025 - val_accuracy: 0.9992\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 7.0183e-04 - val_accuracy: 0.9998\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0041 - val_accuracy: 0.9984\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0088 - val_accuracy: 0.9975\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0040 - val_accuracy: 0.9987\n"
     ]
    }
   ],
   "source": [
    "#<Train your model on the entire training set (50K samples)>\n",
    "history = model.fit(x_train_vec, y_train_vec, batch_size=128, epochs=50, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the model on the test set (5 points)\n",
    "\n",
    "Do NOT use the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 4.4156 - accuracy: 0.6509\n",
      "loss = 4.415625095367432\n",
      "accuracy = 0.6509000062942505\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model performance (testing accuracy) on testing data.\n",
    "loss_and_acc = model.evaluate(x_test_vec, y_test_vec)\n",
    "print('accuracy = ' +str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building model with new structure (25 points)\n",
    "- In this section, you can build your model with adding new layers (e.g, BN layer or dropout layer, ...).\n",
    "- If you want to regularize a ```Conv/Dense layer```, you should place a ```Dropout layer``` before the ```Conv/Dense layer```.\n",
    "- You can try to compare their loss curve and testing accuracy and analyze your findings.\n",
    "- You need to try at lease two different model structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 2, 2, 128)         204928    \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 1, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 274,250\n",
      "Trainable params: 274,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model 2\n",
    "#Adding a third convolutional layer and a Dropout layer before it & Dense layer\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (4,4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Conv2D(128, (5,5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model optimizer and loss function\n",
    "from keras import optimizers\n",
    "model.compile(optimizers.RMSprop(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 16s 39ms/step - loss: 2.8821 - accuracy: 0.1383 - val_loss: 2.0505 - val_accuracy: 0.2206\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.9977 - accuracy: 0.2345 - val_loss: 1.7716 - val_accuracy: 0.3569\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.8275 - accuracy: 0.3131 - val_loss: 1.6346 - val_accuracy: 0.4217\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.6783 - accuracy: 0.3769 - val_loss: 1.5262 - val_accuracy: 0.4700\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.5859 - accuracy: 0.4198 - val_loss: 1.4617 - val_accuracy: 0.4809\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.5074 - accuracy: 0.4528 - val_loss: 1.3440 - val_accuracy: 0.5382\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.4484 - accuracy: 0.4769 - val_loss: 1.2687 - val_accuracy: 0.5657\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 23s 59ms/step - loss: 1.3827 - accuracy: 0.5023 - val_loss: 1.2064 - val_accuracy: 0.5882\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.3322 - accuracy: 0.5236 - val_loss: 1.1374 - val_accuracy: 0.6112\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.2837 - accuracy: 0.5419 - val_loss: 1.1205 - val_accuracy: 0.6243\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 1.2460 - accuracy: 0.5563 - val_loss: 1.0943 - val_accuracy: 0.6286\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.2067 - accuracy: 0.5733 - val_loss: 1.0233 - val_accuracy: 0.6608\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 1.1737 - accuracy: 0.5861 - val_loss: 1.0701 - val_accuracy: 0.6344\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 1.1419 - accuracy: 0.5979 - val_loss: 0.9648 - val_accuracy: 0.6768\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.1160 - accuracy: 0.6063 - val_loss: 0.9536 - val_accuracy: 0.6895\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.0897 - accuracy: 0.6164 - val_loss: 0.9253 - val_accuracy: 0.6898\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 1.0631 - accuracy: 0.6258 - val_loss: 0.8989 - val_accuracy: 0.7078\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 1.0389 - accuracy: 0.6346 - val_loss: 0.8804 - val_accuracy: 0.7062\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 1.0191 - accuracy: 0.6417 - val_loss: 0.8342 - val_accuracy: 0.7383\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.9994 - accuracy: 0.6508 - val_loss: 0.8375 - val_accuracy: 0.7234\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 0.9759 - accuracy: 0.6592 - val_loss: 0.8522 - val_accuracy: 0.7300\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.9605 - accuracy: 0.6641 - val_loss: 0.7874 - val_accuracy: 0.7474\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.9409 - accuracy: 0.6709 - val_loss: 0.7269 - val_accuracy: 0.7778\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.9225 - accuracy: 0.6775 - val_loss: 0.7812 - val_accuracy: 0.7459\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.9086 - accuracy: 0.6853 - val_loss: 0.7091 - val_accuracy: 0.7772\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 0.8924 - accuracy: 0.6877 - val_loss: 0.6688 - val_accuracy: 0.7934\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 0.8803 - accuracy: 0.6921 - val_loss: 0.6916 - val_accuracy: 0.7921\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.8608 - accuracy: 0.6978 - val_loss: 0.6400 - val_accuracy: 0.8046\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.8506 - accuracy: 0.7025 - val_loss: 0.6618 - val_accuracy: 0.7903\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.8348 - accuracy: 0.7097 - val_loss: 0.6558 - val_accuracy: 0.7923\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.8231 - accuracy: 0.7129 - val_loss: 0.6345 - val_accuracy: 0.8020\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.8101 - accuracy: 0.7188 - val_loss: 0.6179 - val_accuracy: 0.8163\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.8023 - accuracy: 0.7204 - val_loss: 0.6137 - val_accuracy: 0.8182\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.7899 - accuracy: 0.7256 - val_loss: 0.5594 - val_accuracy: 0.8278\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 0.7753 - accuracy: 0.7298 - val_loss: 0.5859 - val_accuracy: 0.8181\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.7645 - accuracy: 0.7330 - val_loss: 0.5481 - val_accuracy: 0.8383\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 0.7583 - accuracy: 0.7354 - val_loss: 0.5673 - val_accuracy: 0.8433\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.7466 - accuracy: 0.7398 - val_loss: 0.6405 - val_accuracy: 0.8038\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.7347 - accuracy: 0.7449 - val_loss: 0.5219 - val_accuracy: 0.8368\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 0.7321 - accuracy: 0.7442 - val_loss: 0.5588 - val_accuracy: 0.8233\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.7197 - accuracy: 0.7516 - val_loss: 0.5168 - val_accuracy: 0.8563\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.7128 - accuracy: 0.7504 - val_loss: 0.4779 - val_accuracy: 0.8611\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.7071 - accuracy: 0.7532 - val_loss: 0.4927 - val_accuracy: 0.8615\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.6951 - accuracy: 0.7579 - val_loss: 0.4529 - val_accuracy: 0.8678\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.6862 - accuracy: 0.7608 - val_loss: 0.4344 - val_accuracy: 0.8784\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.6768 - accuracy: 0.7632 - val_loss: 0.4749 - val_accuracy: 0.8577\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 0.6727 - accuracy: 0.7643 - val_loss: 0.4724 - val_accuracy: 0.8591\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.6679 - accuracy: 0.7661 - val_loss: 0.4647 - val_accuracy: 0.8841\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.6628 - accuracy: 0.7678 - val_loss: 0.4472 - val_accuracy: 0.8729\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.6567 - accuracy: 0.7712 - val_loss: 0.4239 - val_accuracy: 0.8871\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store model parameters/loss values\n",
    "history = model.fit(x_train_vec, y_train_vec, batch_size=128, epochs=50, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = range(50)\n",
    "train_loss = history.history['loss']\n",
    "valid_loss = history.history['val_loss']\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, valid_loss, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<Compile your model again (using the same hyper-parameters you tuned above)>\n",
    "model.compile(optimizers.RMSprop(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 17s 41ms/step - loss: 0.6564 - accuracy: 0.7705 - val_loss: 0.4443 - val_accuracy: 0.8809\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.6453 - accuracy: 0.7739 - val_loss: 0.4112 - val_accuracy: 0.8966\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.6352 - accuracy: 0.7797 - val_loss: 0.4717 - val_accuracy: 0.8768\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.6303 - accuracy: 0.7777 - val_loss: 0.3930 - val_accuracy: 0.8929\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.6272 - accuracy: 0.7817 - val_loss: 0.4001 - val_accuracy: 0.8960\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.6259 - accuracy: 0.7805 - val_loss: 0.4031 - val_accuracy: 0.8847\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.6147 - accuracy: 0.7854 - val_loss: 0.3978 - val_accuracy: 0.8865\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.6093 - accuracy: 0.7878 - val_loss: 0.3569 - val_accuracy: 0.9100\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.5975 - accuracy: 0.7892 - val_loss: 0.3956 - val_accuracy: 0.8974\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.6021 - accuracy: 0.7906 - val_loss: 0.3866 - val_accuracy: 0.8970\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.5937 - accuracy: 0.7928 - val_loss: 0.3640 - val_accuracy: 0.8970\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.5947 - accuracy: 0.7919 - val_loss: 0.3494 - val_accuracy: 0.9154\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.5812 - accuracy: 0.7946 - val_loss: 0.3143 - val_accuracy: 0.9127\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 0.5752 - accuracy: 0.8003 - val_loss: 0.3548 - val_accuracy: 0.9133\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.5780 - accuracy: 0.7978 - val_loss: 0.3470 - val_accuracy: 0.9074\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.5727 - accuracy: 0.8002 - val_loss: 0.3595 - val_accuracy: 0.9001\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.5679 - accuracy: 0.8017 - val_loss: 0.3027 - val_accuracy: 0.9236\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 0.5647 - accuracy: 0.8040 - val_loss: 0.3239 - val_accuracy: 0.9172\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 0.5635 - accuracy: 0.8026 - val_loss: 0.3155 - val_accuracy: 0.9171\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.5573 - accuracy: 0.8046 - val_loss: 0.3009 - val_accuracy: 0.9187\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.5564 - accuracy: 0.8067 - val_loss: 0.3018 - val_accuracy: 0.9241\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.5427 - accuracy: 0.8104 - val_loss: 0.3157 - val_accuracy: 0.9219\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.5422 - accuracy: 0.8085 - val_loss: 0.3516 - val_accuracy: 0.9088\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.5403 - accuracy: 0.8111 - val_loss: 0.2990 - val_accuracy: 0.9247\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.5349 - accuracy: 0.8100 - val_loss: 0.2967 - val_accuracy: 0.9333\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.5305 - accuracy: 0.8142 - val_loss: 0.3227 - val_accuracy: 0.9244\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.5331 - accuracy: 0.8154 - val_loss: 0.2885 - val_accuracy: 0.9280\n",
      "Epoch 28/50\n",
      " 15/391 [>.............................] - ETA: 13s - loss: 0.4716 - accuracy: 0.8479"
     ]
    }
   ],
   "source": [
    "#<Train your model on the entire training set (50K samples)>\n",
    "history = model.fit(x_train_vec, y_train_vec, batch_size=128, epochs=50, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.7663 - accuracy: 0.7440\n",
      "accuracy = 0.7440000176429749\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model performance (testing accuracy) on testing data.\n",
    "loss_and_acc = model.evaluate(x_test_vec, y_test_vec)\n",
    "print('accuracy = ' +str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 4, 4, 32)          18464     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4, 4, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 2, 2, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1024)              132096    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,666\n",
      "Trainable params: 194,602\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model 3\n",
    "#Adding a dropout layer, third convolutional layer, Batch Normalization layer for third convolutional layer and different dense layer\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Conv2D(64, (4,4), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model optimizer and loss function\n",
    "from keras import optimizers\n",
    "model.compile(optimizers.RMSprop(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 16s 38ms/step - loss: 1.7642 - accuracy: 0.3568 - val_loss: 1.7532 - val_accuracy: 0.3607\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 1.4224 - accuracy: 0.4881 - val_loss: 1.3861 - val_accuracy: 0.4919\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.2973 - accuracy: 0.5371 - val_loss: 1.3378 - val_accuracy: 0.5163\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.2179 - accuracy: 0.5652 - val_loss: 1.2484 - val_accuracy: 0.5484\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.1592 - accuracy: 0.5881 - val_loss: 1.2478 - val_accuracy: 0.5535\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.1089 - accuracy: 0.6065 - val_loss: 1.0959 - val_accuracy: 0.6090\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 1.0712 - accuracy: 0.6220 - val_loss: 1.0950 - val_accuracy: 0.6037\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 1.0353 - accuracy: 0.6356 - val_loss: 0.9853 - val_accuracy: 0.6485\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.0039 - accuracy: 0.6470 - val_loss: 0.9478 - val_accuracy: 0.6648\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.9791 - accuracy: 0.6583 - val_loss: 0.9360 - val_accuracy: 0.6678\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.9507 - accuracy: 0.6670 - val_loss: 0.9542 - val_accuracy: 0.6613\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.9245 - accuracy: 0.6747 - val_loss: 0.8525 - val_accuracy: 0.7013\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.9088 - accuracy: 0.6812 - val_loss: 0.9301 - val_accuracy: 0.6694\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.8840 - accuracy: 0.6910 - val_loss: 0.9594 - val_accuracy: 0.6601\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.8683 - accuracy: 0.6964 - val_loss: 0.7953 - val_accuracy: 0.7246\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.8519 - accuracy: 0.7034 - val_loss: 0.7941 - val_accuracy: 0.7228\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.8304 - accuracy: 0.7094 - val_loss: 0.8298 - val_accuracy: 0.7060\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.8186 - accuracy: 0.7130 - val_loss: 0.8581 - val_accuracy: 0.6957\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.8015 - accuracy: 0.7191 - val_loss: 0.7282 - val_accuracy: 0.7456\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 0.7860 - accuracy: 0.7250 - val_loss: 0.7473 - val_accuracy: 0.7365\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.7726 - accuracy: 0.7286 - val_loss: 0.7243 - val_accuracy: 0.7478\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.7613 - accuracy: 0.7342 - val_loss: 0.7070 - val_accuracy: 0.7542\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.7508 - accuracy: 0.7374 - val_loss: 0.6956 - val_accuracy: 0.7599\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.7363 - accuracy: 0.7435 - val_loss: 0.7107 - val_accuracy: 0.7515\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.7247 - accuracy: 0.7475 - val_loss: 0.6479 - val_accuracy: 0.7767\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.7137 - accuracy: 0.7502 - val_loss: 0.6327 - val_accuracy: 0.7842\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 19s 50ms/step - loss: 0.7017 - accuracy: 0.7535 - val_loss: 0.6613 - val_accuracy: 0.7734\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.6913 - accuracy: 0.7591 - val_loss: 0.6142 - val_accuracy: 0.7872\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6780 - accuracy: 0.7628 - val_loss: 0.6303 - val_accuracy: 0.7801\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.6697 - accuracy: 0.7668 - val_loss: 0.6437 - val_accuracy: 0.7741\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.6620 - accuracy: 0.7686 - val_loss: 0.5971 - val_accuracy: 0.7919\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.6513 - accuracy: 0.7728 - val_loss: 0.5690 - val_accuracy: 0.8108\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.6439 - accuracy: 0.7761 - val_loss: 0.5647 - val_accuracy: 0.8096\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.6309 - accuracy: 0.7785 - val_loss: 0.5902 - val_accuracy: 0.7936\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.6253 - accuracy: 0.7822 - val_loss: 0.5759 - val_accuracy: 0.8035\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 0.6160 - accuracy: 0.7854 - val_loss: 0.5503 - val_accuracy: 0.8130\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6049 - accuracy: 0.7890 - val_loss: 0.5474 - val_accuracy: 0.8110\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.5969 - accuracy: 0.7912 - val_loss: 0.5062 - val_accuracy: 0.8306\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.5919 - accuracy: 0.7936 - val_loss: 0.5415 - val_accuracy: 0.8106\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.5827 - accuracy: 0.7962 - val_loss: 0.4909 - val_accuracy: 0.8374\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.5737 - accuracy: 0.7978 - val_loss: 0.4979 - val_accuracy: 0.8298\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.5681 - accuracy: 0.8016 - val_loss: 0.5237 - val_accuracy: 0.8185\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.5582 - accuracy: 0.8053 - val_loss: 0.5046 - val_accuracy: 0.8302\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 0.5543 - accuracy: 0.8057 - val_loss: 0.4633 - val_accuracy: 0.8447\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 23s 59ms/step - loss: 0.5449 - accuracy: 0.8097 - val_loss: 0.4732 - val_accuracy: 0.8387\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.5379 - accuracy: 0.8123 - val_loss: 0.4417 - val_accuracy: 0.8546\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.5300 - accuracy: 0.8150 - val_loss: 0.4396 - val_accuracy: 0.8567\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 0.5286 - accuracy: 0.8142 - val_loss: 0.4303 - val_accuracy: 0.8600\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.5189 - accuracy: 0.8195 - val_loss: 0.4318 - val_accuracy: 0.8560\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.5160 - accuracy: 0.8198 - val_loss: 0.4455 - val_accuracy: 0.8518\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store model parameters/loss values\n",
    "history = model.fit(x_train_vec, y_train_vec, batch_size=128, epochs=50, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = range(50)\n",
    "train_loss = history.history['loss']\n",
    "valid_loss = history.history['val_loss']\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, valid_loss, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<Compile your model again (using the same hyper-parameters you tuned above)>\n",
    "model.compile(optimizers.RMSprop(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 17s 40ms/step - loss: 0.5065 - accuracy: 0.8226 - val_loss: 0.4272 - val_accuracy: 0.8570\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.5015 - accuracy: 0.8248 - val_loss: 0.4398 - val_accuracy: 0.8525\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 0.4924 - accuracy: 0.8271 - val_loss: 0.4072 - val_accuracy: 0.8644\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 32s 82ms/step - loss: 0.4881 - accuracy: 0.8297 - val_loss: 0.4169 - val_accuracy: 0.8616\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 41s 105ms/step - loss: 0.4819 - accuracy: 0.8337 - val_loss: 0.4058 - val_accuracy: 0.8617\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 34s 86ms/step - loss: 0.4804 - accuracy: 0.8322 - val_loss: 0.4326 - val_accuracy: 0.8536\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 33s 84ms/step - loss: 0.4761 - accuracy: 0.8325 - val_loss: 0.3767 - val_accuracy: 0.8748\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 30s 78ms/step - loss: 0.4650 - accuracy: 0.8377 - val_loss: 0.4142 - val_accuracy: 0.8623\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.4626 - accuracy: 0.8387 - val_loss: 0.4019 - val_accuracy: 0.8647\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 20s 52ms/step - loss: 0.4554 - accuracy: 0.8411 - val_loss: 0.3778 - val_accuracy: 0.8769\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.4488 - accuracy: 0.8419 - val_loss: 0.4012 - val_accuracy: 0.8656\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.4445 - accuracy: 0.8442 - val_loss: 0.3563 - val_accuracy: 0.8828\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.4428 - accuracy: 0.8444 - val_loss: 0.3556 - val_accuracy: 0.8835\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.4371 - accuracy: 0.8468 - val_loss: 0.3420 - val_accuracy: 0.8878\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.4298 - accuracy: 0.8509 - val_loss: 0.3441 - val_accuracy: 0.8896\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.4243 - accuracy: 0.8510 - val_loss: 0.3369 - val_accuracy: 0.8920\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 0.4241 - accuracy: 0.8519 - val_loss: 0.3653 - val_accuracy: 0.8761\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.4177 - accuracy: 0.8544 - val_loss: 0.3434 - val_accuracy: 0.8880\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.4121 - accuracy: 0.8562 - val_loss: 0.3484 - val_accuracy: 0.8836\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.4094 - accuracy: 0.8569 - val_loss: 0.3211 - val_accuracy: 0.8987\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.4035 - accuracy: 0.8598 - val_loss: 0.3389 - val_accuracy: 0.8874\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 0.3982 - accuracy: 0.8609 - val_loss: 0.3138 - val_accuracy: 0.8988\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 0.3971 - accuracy: 0.8610 - val_loss: 0.3148 - val_accuracy: 0.9001\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 0.3823 - accuracy: 0.8681 - val_loss: 0.3100 - val_accuracy: 0.8989\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 23s 58ms/step - loss: 0.3840 - accuracy: 0.8663 - val_loss: 0.3051 - val_accuracy: 0.8999\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.3812 - accuracy: 0.8661 - val_loss: 0.2997 - val_accuracy: 0.9021\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 21s 53ms/step - loss: 0.3773 - accuracy: 0.8679 - val_loss: 0.2860 - val_accuracy: 0.9102\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.3748 - accuracy: 0.8680 - val_loss: 0.2824 - val_accuracy: 0.9091\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 18s 47ms/step - loss: 0.3684 - accuracy: 0.8705 - val_loss: 0.3405 - val_accuracy: 0.8787\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 18s 46ms/step - loss: 0.3641 - accuracy: 0.8730 - val_loss: 0.2703 - val_accuracy: 0.9173\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.3600 - accuracy: 0.8743 - val_loss: 0.2825 - val_accuracy: 0.9090\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 0.3568 - accuracy: 0.8766 - val_loss: 0.2958 - val_accuracy: 0.9011\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 0.3512 - accuracy: 0.8790 - val_loss: 0.2637 - val_accuracy: 0.9176\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.3501 - accuracy: 0.8782 - val_loss: 0.2745 - val_accuracy: 0.9150\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.3457 - accuracy: 0.8791 - val_loss: 0.2630 - val_accuracy: 0.9167\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.3438 - accuracy: 0.8807 - val_loss: 0.2504 - val_accuracy: 0.9228\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 0.3368 - accuracy: 0.8824 - val_loss: 0.2555 - val_accuracy: 0.9208\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.3313 - accuracy: 0.8855 - val_loss: 0.2288 - val_accuracy: 0.9334\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.3292 - accuracy: 0.8854 - val_loss: 0.2515 - val_accuracy: 0.9206\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 20s 50ms/step - loss: 0.3303 - accuracy: 0.8853 - val_loss: 0.2433 - val_accuracy: 0.9251\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.3224 - accuracy: 0.8880 - val_loss: 0.2273 - val_accuracy: 0.9341\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 21s 54ms/step - loss: 0.3188 - accuracy: 0.8884 - val_loss: 0.2623 - val_accuracy: 0.9154\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.3167 - accuracy: 0.8887 - val_loss: 0.2553 - val_accuracy: 0.9141\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.3139 - accuracy: 0.8915 - val_loss: 0.2194 - val_accuracy: 0.9370\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.3094 - accuracy: 0.8932 - val_loss: 0.2264 - val_accuracy: 0.9345\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.3095 - accuracy: 0.8920 - val_loss: 0.2130 - val_accuracy: 0.9346\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.3033 - accuracy: 0.8929 - val_loss: 0.2339 - val_accuracy: 0.9243\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.2991 - accuracy: 0.8962 - val_loss: 0.2198 - val_accuracy: 0.9332\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.2967 - accuracy: 0.8965 - val_loss: 0.2162 - val_accuracy: 0.9325\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.2928 - accuracy: 0.8985 - val_loss: 0.2191 - val_accuracy: 0.9309\n"
     ]
    }
   ],
   "source": [
    "#<Train your model on the entire training set (50K samples)>\n",
    "history = model.fit(x_train_vec, y_train_vec, batch_size=128, epochs=50, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.8194 - accuracy: 0.7554\n",
      "accuracy = 0.7554000020027161\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model performance (testing accuracy) on testing data.\n",
    "loss_and_acc = model.evaluate(x_test_vec, y_test_vec)\n",
    "print('accuracy = ' +str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
